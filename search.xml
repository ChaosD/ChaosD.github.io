<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2020/07/29/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Ceph源码阅读(1)——librbd对rados接口调用</title>
    <url>/2020/07/29/Ceph%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="1-1-Librados"><a href="#1-1-Librados" class="headerlink" title="1.1 Librados"></a>1.1 Librados</h3><p>Ceph rados分布式存储提供了多种语言的api接口，封装在librados库中。客户可以在客户端调用librados，完成对远端的rados分布式存储系统的访问。我们可以在源码目录中打开librados中的api文件夹，查看相关接口。</p>
<p>librados就是操作rados对象存储的接口。 其接口分为两种：一个是c 接口，其定义在include/librados.h 中。 一个是 c++接口，定义在include/librados.hpp中，实现都在<a href="http://librados.cc/">librados.cc</a>中实现。</p>
<p>接口主要分为五类[^1]：</p>
<ul>
<li><strong>ceph集群句柄（rados client类的实例）</strong>的创建和销毁，配置，连接等，<strong>pool</strong>的创建和销毁，<strong>io上下文（ioctx）</strong>的创建和销毁等。<ul>
<li>创建一个集群句柄</li>
<li>根据配置文件，命令行参数，环境变量<strong>配置</strong>集群句柄</li>
<li>连接集群，相当于使rados client能够实时通信</li>
<li><strong>创建pool</strong>，配置不同的 crush分布策略，复制级别，位置策略等等</li>
<li><strong>io上下文</strong>的创建及获取</li>
</ul>
</li>
<li><strong>快照相关接口</strong>，librados支持对于整个pool的快照，接口包括快照的创建和销毁，到对应快照版本的回滚，快照查询等等。</li>
<li><strong>同步IO操作接口</strong>，包括读，写，覆盖写，追加写，对象数据克隆，删，截断，获取和设置指定的扩展属性，批量获取扩展属性，迭代器遍历扩展属性，特殊键值对获取等等</li>
<li><strong>异步IO操作接口</strong>包括异步读，异步写，异步覆盖写，异步追加写，异步删，librados还提供了对象的监视功能，通过rados_watch可以注册回调，当对象发生变化时会回调通知上层。</li>
<li><strong>io操作组原子操作</strong>，即可以把对同一个对象的一系列io操作放到一个组里面，最后保证加入到组里的所有io操作保持原子性，要么全部成功，要么全部失败，而不会给用户呈现出文件系统不一致的问题。</li>
</ul>
<p>下述是客户端使用librados连接集群并读写对象的一个实例[^2]：</p>
<ol>
<li>获得集群的句柄，并连接到集群的某个Monitor中.以获得Cluster Map；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">cluster_name</span><span class="params">(<span class="string">&quot;ceph&quot;</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">user_name</span><span class="params">(<span class="string">&quot;client.admin&quot;</span>)</span></span>;</span><br><span class="line">librados::Rados cluster ;</span><br><span class="line">cluster.init2(user_name.c_str(), cluster_name.c_str(),  <span class="number">0</span>);</span><br><span class="line">cluster.conf_read_file(<span class="string">&quot;/etc/ceph/ceph.conf&quot;</span>);</span><br><span class="line">cluster.<span class="built_in">connect</span>();</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建IO上下文，并绑定一个已经存在的存储池；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">librados::IoCtx io_ctx ;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">pool_name</span><span class="params">(<span class="string">&quot;data&quot;</span>)</span></span>;</span><br><span class="line">cluster.ioctx_create(pool_name.c_str(), io_ctx);</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>同步写入一个对象；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">librados::bufferlist bl;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">objectId</span><span class="params">(<span class="string">&quot;hw&quot;</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">objectContent</span><span class="params">(<span class="string">&quot;Hello World!&quot;</span>)</span></span>;</span><br><span class="line">bl.append(objectContent);</span><br><span class="line">io_ctx.<span class="built_in">write</span>(objectId, bl, objectContent.<span class="built_in">size</span>(),  <span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>为该对象添加扩展属性；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">librados::bufferlist lang_bl;</span><br><span class="line">lang_bl.append(<span class="string">&quot;en_US&quot;</span>);</span><br><span class="line">io_ctx.setxattr(objectId,  <span class="string">&quot;lang&quot;</span>, lang_bl);</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>异步读取对象；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">librados::bufferlist read_buf;</span><br><span class="line"><span class="keyword">int</span> read_len  =  <span class="number">4194304</span>;</span><br><span class="line">librados::AioCompletion  *read_completion  =  librados::Rados::aio_create_completion();</span><br><span class="line">io_ctx.aio_read(objectId, read_completion,  &amp;read_buf, read_len,  <span class="number">0</span> );</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>断开连接</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">io_ctx.<span class="built_in">close</span>();</span><br><span class="line">cluster.<span class="built_in">shutdown</span>();</span><br></pre></td></tr></table></figure>

<h3 id="1-2-librbd"><a href="#1-2-librbd" class="headerlink" title="1.2 librbd"></a>1.2 librbd</h3><p>Librbd是Ceph提供块存储的库，它实现了RBD接口，基于Librados实现了对块设备的基本操作。[^3]librbd的基本架构及功能如下图所示。</p>
<p><img src= "/img/loading.gif" data-src="https://zhoubofsy.github.io/images/ceph/librbd_frame.png" alt="librbd的基本架构"></p>
<p>Ceph librbd通过调用librados的接口，完成了块设备的接口封装。下面将讲解librbd中的具体实现情况。</p>
<h2 id="2-librbd接口实现"><a href="#2-librbd接口实现" class="headerlink" title="2. librbd接口实现"></a>2. librbd接口实现</h2><p>首先，librbd中调用的rados类如下：，包括：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>声明</th>
<th>定义</th>
<th align="left">注释</th>
</tr>
</thead>
<tbody><tr>
<td>librados::(v14_2_0::)IoCtx</td>
<td>\include\rados\librados.hpp</td>
<td>src\librados\librados_cxx.cc</td>
<td align="left">rados的上下文实例</td>
</tr>
<tr>
<td>librados::(v14_2_0::)AioCompletion</td>
<td>\include\rados\librados.hpp</td>
<td>src\librados\librados_cxx.cc</td>
<td align="left">rados异步操作的回调实现</td>
</tr>
<tr>
<td>librados::(v14_2_0::)Rados</td>
<td>\include\rados\librados.hpp</td>
<td>src\librados\librados_cxx.cc</td>
<td align="left">rados实例</td>
</tr>
</tbody></table>
<p>其中IoCtx是rados的上下文实例，创建时需要绑定一个<strong>存储池</strong>（pool），封装了大量对存储池的操作函数，比如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">create</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; oid, <span class="keyword">bool</span> exclusive)</span></span>; <span class="comment">//创建object</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">write</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; oid, bufferlist&amp; bl, <span class="keyword">size_t</span> len, <span class="keyword">uint64_t</span> off)</span> <span class="comment">//从偏移处修改某个对象</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">append</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; oid, bufferlist&amp; bl, <span class="keyword">size_t</span> len)</span></span>;<span class="comment">// 在对象末尾追加</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aio_read</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; oid, AioCompletion *c,</span></span></span><br><span class="line"><span class="function"><span class="params">    bufferlist *pbl, <span class="keyword">size_t</span> len, <span class="keyword">uint64_t</span> off, <span class="keyword">uint64_t</span> snapid)</span></span>;<span class="comment">// 异步读</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aio_write</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; oid, AioCompletion *c, <span class="keyword">const</span> bufferlist&amp; bl,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">size_t</span> len, <span class="keyword">uint64_t</span> off)</span></span>;<span class="comment">//异步写</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>从以上源码可知，IoCtx中提供了对rados中对象的创建、删除、读写等同步操作接口以及除了同步操作，其中也提供异步操作的接口。</p>
<p>而AioCompletion这个类十分特别。他提供了回调函数的相关接口，即可以简单的理解成，AioCompletion表示我们需要进行的回调函数。</p>
<h3 id="2-1-librbd使用实例"><a href="#2-1-librbd使用实例" class="headerlink" title="2.1 librbd使用实例"></a>2.1 librbd使用实例</h3><p>Ceph的rbd设备使用方法与对象存储的使用有很大的相关性，原因在于rbd本质上是对于rados的再次封装。相关接口可以直接查看*/include/rbd/librbd.hpp*查看。</p>
<ol>
<li>获得集群的句柄，并连接到集群的某个Monitor中.以获得Cluster Map；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">cluster_name</span><span class="params">(<span class="string">&quot;ceph&quot;</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">user_name</span><span class="params">(<span class="string">&quot;client.admin&quot;</span>)</span></span>;</span><br><span class="line">librados::Rados cluster ;</span><br><span class="line">cluster.init2(user_name.c_str(), cluster_name.c_str(),  <span class="number">0</span>);</span><br><span class="line">cluster.conf_read_file(<span class="string">&quot;/etc/ceph/ceph.conf&quot;</span>);</span><br><span class="line">cluster.<span class="built_in">connect</span>();</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建IO上下文，并绑定一个已经存在的存储池；</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">librados::IoCtx io_ctx;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">pool_name</span><span class="params">(<span class="string">&quot;data&quot;</span>)</span></span>;</span><br><span class="line">cluster.ioctx_create(pool_name.c_str(), io_ctx);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建rbd设备，即我们需要的虚拟块设备,并创建image结构，这里该结构将<em>myimag</em>e与<em>ioctx</em> 联系起来，后面可以通过image结构直接找到<em>ioctx</em>。这里会将ioctx复制两份，分为为<em>data_ioctx</em>和<em>md_ctx</em>。见明知意，一个用来处理rbd的存储数据，一个用来处理rbd的管理数据。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">rbd_inst.create(ioctx,&#x27;myimage&#x27;,size);</span><br><span class="line">image = rbd.Image(ioctx,&#x27;myimage&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>再次之后，我们就可以通过调用image的相关接口，如aio_write，aio_read对该块设备进行读写操作。</p>
<h3 id="2-2-librbd读写流程"><a href="#2-2-librbd读写流程" class="headerlink" title="2.2 librbd读写流程"></a>2.2 librbd读写流程</h3><ol>
<li><em>image.read(data,0)<em>，通过image开始了一个写请求的生命的开始。这里指明了request的两个基本要素 buffer=data 和 offset=0。</em>image.read(data,0)<em>将会转化为librbd.cc文件中的</em>Image::read()</em> 函数，该函数中调用了ImageRequestWQ中的read的函数。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">ssize_t</span> <span class="title">Image::read</span><span class="params">(<span class="keyword">uint64_t</span> ofs, <span class="keyword">size_t</span> len, bufferlist&amp; bl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ImageCtx *ictx = (ImageCtx *)ctx;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">int</span> r = ictx-&gt;io_work_queue-&gt;<span class="built_in">read</span>(ofs, len, io::ReadResult&#123;&amp;bl&#125;, <span class="number">0</span>);</span><br><span class="line">  tracepoint(librbd, read_exit, r);</span><br><span class="line">  <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>ImageRequestWQ::read中的实现。该函数的具体实现在ImageRequestWQ.cc文件中。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ssize_t</span> ImageRequestWQ&lt;I&gt;::<span class="built_in">read</span>(<span class="keyword">uint64_t</span> off, <span class="keyword">uint64_t</span> len,</span><br><span class="line">                ReadResult &amp;&amp;read_result, <span class="keyword">int</span> op_flags) &#123;</span><br><span class="line">  CephContext *cct = m_image_ctx.cct;</span><br><span class="line">  ldout(cct, <span class="number">20</span>) &lt;&lt; <span class="string">&quot;ictx=&quot;</span> &lt;&lt; &amp;m_image_ctx &lt;&lt; <span class="string">&quot;, off=&quot;</span> &lt;&lt; off &lt;&lt; <span class="string">&quot;, &quot;</span></span><br><span class="line">                 &lt;&lt; <span class="string">&quot;len = &quot;</span> &lt;&lt; len &lt;&lt; dendl;</span><br><span class="line"></span><br><span class="line">  C_SaferCond cond;  <span class="comment">//---a</span></span><br><span class="line">  AioCompletion *c = AioCompletion::create(&amp;cond); <span class="comment">//---b</span></span><br><span class="line">  aio_read(c, off, len, <span class="built_in">std</span>::<span class="built_in">move</span>(read_result), op_flags, <span class="literal">false</span>); <span class="comment">//---c</span></span><br><span class="line">  <span class="keyword">return</span> cond.wait(); <span class="comment">//---d</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>a. 创建了一个等待机制的上下文。</li>
<li>b. 根据上下文创建回调函数，即aio_read完成后会调用的函数。</li>
<li>c. 该函数aio_read会继续处理这个读请求。</li>
<li>d. 知道cond.wait()结束，即aio_read调用回调函数时，程序结束。</li>
</ul>
<p>由上述步骤可知，ceph的同步读写实际上是在异步读写的基础上，加上同步机制实现的。</p>
<ol start="3">
<li>再来看看aio_write 拿到了 请求的offset和buffer会做点什么呢？</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> I&gt;</span><br><span class="line"><span class="keyword">void</span> ImageRequestWQ&lt;I&gt;::aio_read(AioCompletion *c, <span class="keyword">uint64_t</span> off, <span class="keyword">uint64_t</span> len,</span><br><span class="line">                 ReadResult &amp;&amp;read_result, <span class="keyword">int</span> op_flags,</span><br><span class="line">                 <span class="keyword">bool</span> native_async) &#123;</span><br><span class="line">  CephContext *cct = m_image_ctx.cct;</span><br><span class="line">  ...</span><br><span class="line">  <span class="function">RWLock::RLocker <span class="title">owner_locker</span><span class="params">(m_image_ctx.owner_lock)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (m_image_ctx.non_blocking_aio || writes_blocked() || !writes_empty() ||</span><br><span class="line">      require_lock_on_read()) &#123; <span class="comment">//---a</span></span><br><span class="line">    <span class="built_in">queue</span>(ImageDispatchSpec&lt;I&gt;::create_read_request(</span><br><span class="line">            m_image_ctx, c, &#123;&#123;off, len&#125;&#125;, <span class="built_in">std</span>::<span class="built_in">move</span>(read_result), op_flags,</span><br><span class="line">            trace));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;    <span class="comment">//---b</span></span><br><span class="line">    c-&gt;start_op();</span><br><span class="line">    ImageRequest&lt;I&gt;::aio_read(&amp;m_image_ctx, c, &#123;&#123;off, len&#125;&#125;,</span><br><span class="line">                  <span class="built_in">std</span>::<span class="built_in">move</span>(read_result), op_flags, trace);</span><br><span class="line">    finish_in_flight_io();</span><br><span class="line">  &#125;</span><br><span class="line">  trace.event(<span class="string">&quot;finish&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里对输入的情况进行讨论。</p>
<ul>
<li>a. 如果输入后，发现写入队列不为空/日志被其他程序打开/写入区域已被阻塞/需要锁定当前数据，就会将当前写请求加入读写队列中。</li>
<li>b. 否则直接调用ImageRequet::aio_read操作进行读取。</li>
</ul>
<p>这里直接查看第二处的执行流程。实际上，在<em>ImageRequest::aio_read</em>函数中，读取请求按照下图的次序进入ImageReadRequest::send_reques*中，在该函数将对于块设备的读写请求转化为对于对象的读写请求。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">    D[ImageRequestWQ::aio_read] --&gt; A</span><br><span class="line">    A[ImageRequest::aio_read] --&gt;B[ImageRequest::send]</span><br><span class="line">    B --&gt; C[ImageWriteRequest::send_request]</span><br></pre></td></tr></table></figure>



<ol start="4">
<li><em>ImageReadRequest::send_request</em>这个函数主要完成了块设备分割的功能。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> ImageReadRequest&lt;I&gt;::send_request() &#123;</span><br><span class="line">  I &amp;image_ctx = <span class="keyword">this</span>-&gt;m_image_ctx;</span><br><span class="line">  CephContext *cct = image_ctx.cct;</span><br><span class="line">  ...</span><br><span class="line">      Striper::file_to_extents(cct, image_ctx.format_string, &amp;image_ctx.layout,</span><br><span class="line">                               extent.first, extent.second, <span class="number">0</span>, object_extents,</span><br><span class="line">                               buffer_ofs); <span class="comment">// ---a</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;object_extent : object_extents) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;extent : object_extent.second) &#123;</span><br><span class="line">      <span class="keyword">auto</span> req_comp = <span class="keyword">new</span> io::ReadResult::C_ObjectReadRequest(</span><br><span class="line">        aio_comp, extent.offset, extent.length,</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">move</span>(extent.buffer_extents));</span><br><span class="line">      <span class="keyword">auto</span> req = ObjectDispatchSpec::create_read(</span><br><span class="line">        &amp;image_ctx, OBJECT_DISPATCH_LAYER_NONE, extent.oid.name,</span><br><span class="line">        extent.objectno, extent.offset, extent.length, snap_id, m_op_flags,</span><br><span class="line">        <span class="keyword">this</span>-&gt;m_trace, &amp;req_comp-&gt;bl, &amp;req_comp-&gt;extent_map, req_comp);</span><br><span class="line">      req-&gt;send();  <span class="comment">// ---b</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  aio_comp-&gt;<span class="built_in">put</span>();</span><br><span class="line"></span><br><span class="line">  image_ctx.perfcounter-&gt;inc(l_librbd_rd);</span><br><span class="line">  image_ctx.perfcounter-&gt;inc(l_librbd_rd_bytes, buffer_ofs);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>a. 根据请求的大小需要将这个请求按着object进行划分，由函数<em>file_to_extents</em>进行处理，处理完成后按着object进行保存在extents中。该函数完成了原始请求的拆分。</li>
</ul>
<blockquote>
<p>一个rbd设备是有很多的object组成，也就是需要将rbd设备进行切块，每一个块叫做object，每个object的大小默认为4M，也可以自己指定。file_to_extents函数将这个大的请求分别映射到object上去，拆成了很多小的请求如下图。最后映射的结果保存在ObjectExtent中。</p>
<p><img src= "/img/loading.gif" data-src="http://static.oschina.net/uploads/space/2015/1119/145240_0zUe_2460844.jpg" alt="img"></p>
<p>原本的offset是指在rbd内的偏移量(写入rbd的位置)，经过file_to_extents后，转化成了一个或者多个object的内部的偏移量offset0。这样转化后处理一批这个object内的请求。</p>
</blockquote>
<ul>
<li>b. 调用<em>ObjectDispatchSpec::send</em>，将分割后的对象读请求进行分发、处理。</li>
</ul>
<ol start="5">
<li><em>ObjectDispatchSpac::send</em>函数将会按照下图次序进入函数*ImageReadRequest::send_request()*：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">    D[ObjectDispatchSpac::send] --&gt; A[ObjectDispatcherInterface::send]</span><br><span class="line">    A --&gt;B[ObjectDispatcher::send]</span><br><span class="line">    B --&gt; C[ImageReadRequest::send_request]</span><br></pre></td></tr></table></figure>



<p>函数<em>ImageReadRequest::send_request</em>将创建一个SendVistor，由观察者继续读写流程。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> ObjectDispatcher&lt;I&gt;::send(ObjectDispatchSpec* object_dispatch_spec) &#123;</span><br><span class="line">  <span class="keyword">auto</span> cct = m_image_ctx-&gt;cct;</span><br><span class="line">      ...</span><br><span class="line">    <span class="keyword">bool</span> handled = boost::apply_visitor(</span><br><span class="line">      SendVisitor&#123;object_dispatch, object_dispatch_spec&#125;,</span><br><span class="line">      object_dispatch_spec-&gt;request);</span><br><span class="line">    object_dispatch_meta.async_op_tracker-&gt;finish_op(); <span class="comment">// 创建SendVistor</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// handled ops will resume when the dispatch ctx is invoked</span></span><br><span class="line">    <span class="keyword">if</span> (handled) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  object_dispatch_spec-&gt;dispatcher_ctx.complete(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ol start="6">
<li>进入<em>ObjectDispatcher::SendVisitor</em>函数，发现读流程如下图，最终调用了<em>read_object</em>。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">    D[ObjectDispatcher::SendVisitor] --&gt; A[ObjectDispatchInterface::read]</span><br><span class="line">    A --&gt;B[ObjectDispatch::read]</span><br><span class="line">    B --&gt; C[ObjectReadRequest::read]</span><br><span class="line">    C --&gt; E[ObjectReadRequest::read_object]</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<p>最终在函数<em>read_object</em>中调用了rados对于对象的读写接口。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> ObjectReadRequest&lt;I&gt;::read_object() &#123;</span><br><span class="line">  I *image_ctx = <span class="keyword">this</span>-&gt;m_ictx;</span><br><span class="line">  ...</span><br><span class="line">  librados::ObjectReadOperation op; <span class="comment">// ---a</span></span><br><span class="line">  ...</span><br><span class="line">  librados::AioCompletion *rados_completion = util::create_rados_callback&lt;</span><br><span class="line">    ObjectReadRequest&lt;I&gt;, &amp;ObjectReadRequest&lt;I&gt;::handle_read_object&gt;(<span class="keyword">this</span>); <span class="comment">// ---b</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">int</span> flags = image_ctx-&gt;get_read_flags(<span class="keyword">this</span>-&gt;m_snap_id);</span><br><span class="line">  <span class="keyword">int</span> r = image_ctx-&gt;data_ctx.aio_operate(</span><br><span class="line">    data_object_name(<span class="keyword">this</span>-&gt;m_ictx, <span class="keyword">this</span>-&gt;m_object_no), rados_completion, &amp;op,</span><br><span class="line">    flags, <span class="literal">nullptr</span>,</span><br><span class="line">    (<span class="keyword">this</span>-&gt;m_trace.valid() ? <span class="keyword">this</span>-&gt;m_trace.get_info() : <span class="literal">nullptr</span>)); <span class="comment">// ---c</span></span><br><span class="line">  ceph_assert(r == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  rados_completion-&gt;<span class="built_in">release</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>a. 创建对象操作。这里将根据具体情况选择进行<em>read</em>或<em>sparse_read</em>操作。</li>
<li>b. 创建回调函数。这里创建了读取操作的回调函数，回调函数将会返回读取道德结果</li>
<li>c.  <code>int r = image_ctx-&gt;data_ctx.aio_operate</code>语句中，data_ctx即为当前image所在存储池的IoCtx对象。通过调用IoCtx对象的接口，最终将读写请求交付到了librados的相关接口。</li>
</ul>
<h3 id="2-3-librbd小结"><a href="#2-3-librbd小结" class="headerlink" title="2.3 librbd小结"></a>2.3 librbd小结</h3><p>上文已经介绍，librbd的基本功能是将块存储的请求转化为对象存储。事实上，librbd实现的功能远远不止这些。包括调用rados的snap机制完成<strong>快照</strong>，借助journal完成<strong>镜像</strong>功能，并能在故障后进行<strong>故障恢复</strong>，完成<strong>回滚</strong>操作等等。</p>
<p>为了保证块设备的正常运行，librbd中还需要管理大量的其他数据，这些数据都会以对象的形式存储在rados分布式存储系统中。包括：</p>
<ul>
<li>元数据：rbd _dircetory，rbd_id，rbd_head，rbd_object_map等</li>
<li>cache数据：cache_object，cache_parent，cache_writeAround等</li>
<li>日志数据：journal</li>
</ul>
<p>因为需要实现的功能太过繁杂，librbd的代码十分复杂。对librbd进行全文件夹搜索，发现其对librados的接口调用多达<strong>1042</strong>处。</p>
<p>[^1]: <a href="https://blog.csdn.net/hit1944/article/details/38330975">ceph的librados api解释</a><br>[^2]: <a href="https://my.oschina.net/u/2271251/blog/369820">ceph librados接口说明</a><br>[^3]: <a href="https://blog.csdn.net/csnd_pan/article/details/78728743">Ceph学习——Librbd块存储库与RBD读写流程源码分析</a><br>[^4]: <a href="https://zhoubofsy.github.io/2017/01/22/storage/ceph/librbd-frame-analyse/">librbd 架构分析</a><br>[^5]: <a href="https://my.oschina.net/u/2460844/blog/532755">ceph的数据存储之路(4) —– rbd client 端的数据请求处理</a><br>[^6]: <a href="https://docs.ceph.com/docs/master/rados/operations/cache-tiering/">Ceph Tiering官方文档</a> </p>
]]></content>
      <categories>
        <category>Ceph</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
        <tag>RBD</tag>
        <tag>RADOS</tag>
        <tag>c++</tag>
      </tags>
  </entry>
</search>
